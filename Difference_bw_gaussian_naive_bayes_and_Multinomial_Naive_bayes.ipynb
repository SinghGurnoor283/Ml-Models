{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Gaussian NaÃ¯ve Bayes (GNB)\n",
        "\n",
        "Assumes features follow a Gaussian (normal) distribution.\n",
        "\n",
        "Best suited for continuous data (like Iris).\n",
        "\n",
        "Formula used for each feature:\n",
        "\n",
        "Multinomial NaÃ¯ve Bayes (MNB)\n",
        "Assumes features are counts or frequencies (like word counts in text).\n",
        "\n",
        "Typically used in text classification.\n",
        "\n",
        "Not ideal for continuous features, unless transformed (e.g., discretized or scaled as counts)."
      ],
      "metadata": {
        "id": "LYUMsKTaVQ8Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3M9Y9yhVLId",
        "outputId": "eda7580e-cb9d-4534-b22b-38813e060e77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0,\n",
              " array([[10,  0,  0],\n",
              "        [ 0,  9,  0],\n",
              "        [ 0,  0, 11]]),\n",
              " '              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00        10\\n           1       1.00      1.00      1.00         9\\n           2       1.00      1.00      1.00        11\\n\\n    accuracy                           1.00        30\\n   macro avg       1.00      1.00      1.00        30\\nweighted avg       1.00      1.00      1.00        30\\n',\n",
              " 0.9,\n",
              " array([[10,  0,  0],\n",
              "        [ 0,  9,  0],\n",
              "        [ 0,  3,  8]]),\n",
              " '              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00        10\\n           1       0.75      1.00      0.86         9\\n           2       1.00      0.73      0.84        11\\n\\n    accuracy                           0.90        30\\n   macro avg       0.92      0.91      0.90        30\\nweighted avg       0.93      0.90      0.90        30\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data  # feature matrix\n",
        "y = iris.target  # target labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "mnb = MultinomialNB()\n",
        "\n",
        "gnb.fit(X_train, y_train)\n",
        "mnb.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred_gnb = gnb.predict(X_test)\n",
        "y_pred_mnb = mnb.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
        "conf_matrix_gnb = confusion_matrix(y_test, y_pred_gnb)\n",
        "class_report_gnb = classification_report(y_test,y_pred_gnb)\n",
        "\n",
        "accuracy_mnb = accuracy_score(y_test, y_pred_mnb)\n",
        "conf_matrix_mnb = confusion_matrix(y_test, y_pred_mnb)\n",
        "class_report_mnb = classification_report(y_test, y_pred_mnb)\n",
        "\n",
        "accuracy_gnb, conf_matrix_gnb, class_report_gnb, accuracy_mnb, conf_matrix_mnb, class_report_mnb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gaussian Naive Bayes (GNB) Results\n",
        "\n",
        "Accuracy: 1.0 â†’ Perfect classification (100% correct predictions).\n",
        "\n",
        "ðŸ‘‰ Why so good?\n",
        "GaussianNB assumes features follow a Gaussian (normal) distribution, which matches the Iris dataset pretty well since its features (like petal length/width) are continuous and roughly normally distributed. Thatâ€™s why it achieved perfect accuracy.\n",
        "\n",
        "ðŸ”¹ Multinomial Naive Bayes (MNB) Results\n",
        "\n",
        "Accuracy: 0.90 â†’ 90% correct predictions.\n",
        "\n",
        "ðŸ‘‰ Why weaker?\n",
        "MultinomialNB assumes features are counts (non-negative integers), like word frequencies in text classification"
      ],
      "metadata": {
        "id": "2QTS_K3_VYFn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MyXrRo0WVUA6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}